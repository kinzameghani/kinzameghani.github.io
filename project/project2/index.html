<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Kinza Meghani" />
    
    <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.79.0" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="/"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="/post/">BLOG</a></li>
        
        <li><a href="/projects/">PROJECTS</a></li>
        
        <li><a href="/resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="/project/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         January 1, 0001 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="guidelines-and-rubric" class="section level2">
<h2>Guidelines and Rubric</h2>
<p>#Introduction
My dataset consists of 1,138 people and the charges of their medical costs billed by their health insurance. The other main variables include their age, sex, BMI, number of children, smoker status, and residential region across the US. An interesting thing to see is if any of these factors predict higher insurance charges.</p>
<pre class="r"><code>insurance &lt;- read.csv(&quot;insurance.csv&quot;)
glimpse(insurance)</code></pre>
<pre><code>## Rows: 1,338
## Columns: 7
## $ age &lt;int&gt; 19, 18, 28, 33, 32, 31, 46, 37, 37, 60, 25,
62, 23, 56, 27, 19, 52, 23, 56, 30, …
## $ sex &lt;fct&gt; female, male, male, male, male, female,
female, female, male, female, male, fema…
## $ bmi &lt;dbl&gt; 27.900, 33.770, 33.000, 22.705, 28.880,
25.740, 33.440, 27.740, 29.830, 25.840, …
## $ children &lt;int&gt; 0, 1, 3, 0, 0, 0, 1, 3, 2, 0, 0, 0, 0,
0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 2, 3, 0,…
## $ smoker &lt;fct&gt; yes, no, no, no, no, no, no, no, no, no,
no, yes, no, no, yes, no, no, no, no, y…
## $ region &lt;fct&gt; southwest, southeast, southeast,
northwest, northwest, southeast, southeast, nor…
## $ charges &lt;dbl&gt; 16884.924, 1725.552, 4449.462,
21984.471, 3866.855, 3756.622, 8240.590, 7281.506…</code></pre>
<p>#MANOVA</p>
<pre class="r"><code>#MANOVA assumptions
library(rstatix)

group &lt;- insurance$region 
DVs &lt;- insurance %&gt;% select(age,bmi,children,charges)

#Test multivariate normality for each group (null: assumption met)
sapply(split(DVs,group), mshapiro_test)</code></pre>
<pre><code>## northeast northwest southeast southwest
## statistic 0.7599805 0.8281628 0.9703858 0.9443837
## p.value 2.038125e-21 2.55156e-18 9.153024e-07
1.030595e-09</code></pre>
<pre class="r"><code>#If any p&lt;.05, stop. If not, test homogeneity of covariance matrices -&gt; Since p&lt;0.05, I don&#39;t need to use the tests below.

#Box&#39;s M test (null: assumption met)
#box_m(DVs, group)
#View covariance matrices for each group
#lapply(split(DVs,group), cov)

#MANOVA
man1&lt;-manova(cbind(age,bmi,children,charges)~region, data=insurance)
summary(man1)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## region 3 0.088794 10.164 12 3999 &lt; 2.2e-16 ***
## Residuals 1334
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>#ANOVAs
summary.aov(man1) </code></pre>
<pre><code>## Response age :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## region 3 47 15.782 0.0798 0.971
## Residuals 1334 263878 197.810
##
## Response bmi :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## region 3 4056 1351.96 39.495 &lt; 2.2e-16 ***
## Residuals 1334 45664 34.23
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response children :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## region 3 3.13 1.0433 0.7175 0.5416
## Residuals 1334 1939.82 1.4541
##
## Response charges :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## region 3 1.3008e+09 433586560 2.9696 0.03089 *
## Residuals 1334 1.9477e+11 146007093
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>#post-hoc t tests
pairwise.t.test(insurance$bmi, insurance$region, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  insurance$bmi and insurance$region 
## 
##           northeast northwest southeast
## northwest 0.9544    -         -        
## southeast &lt; 2e-16   &lt; 2e-16   -        
## southwest 0.0020    0.0024    8.5e-10  
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(insurance$charges, insurance$region, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  insurance$charges and insurance$region 
## 
##           northeast northwest southeast
## northwest 0.2974    -         -        
## southeast 0.1501    0.0121    -        
## southwest 0.2643    0.9406    0.0097   
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>#probability of one type I error: 1 MANOVA, 4 ANOVAs, 12 t-tests 
1-(0.95^17)</code></pre>
<pre><code>## [1] 0.5818797</code></pre>
<pre class="r"><code>#bonferroni correction
0.5/17</code></pre>
<pre><code>## [1] 0.02941176</code></pre>
<p>A one-way MANOVA was conducted to determine the effects of age, BMI, number of children, and insurance charges on which regions in the U.S. an individual is from. Significant differences were found among the four regions for at least one factor (Pillai trace = 0.089, F=10.164, p&lt;0.0001). Univariate ANOVAs fo reach dependennt variable were created as a follow up, using Bonferroni method for controlling type 1 error. Only two of the univariates were signifcicant, BMI and insurance charges (F=39.495, p&lt;0.0001, and F=2.97, p&lt;0.05), however, insurance charges were not considered significant after correction. Post hoc analysis was performed conductinng pairwise comparisons to determine which regions differed in BMI annd charges. BMI significantly differed between the southeast and northeast, between the southeast and the northwest, and between the southwest and the northeast, northwest,and southeast. Charges were significantly different between the southwest and northwest and between the southwest and southeast. These were all found to be significant even after adjusting to the bonferroni level of significance.</p>
<p>I performed 1 MANOVA test, 4 ANOVA tests, and 12 pos-hoc t-tests resulting in a total of 17 tests. This makes the probability of at least one type-1 error 0.582. We should use a bonferroni level of 0.029 to adjust for multiple comparisons.</p>
<p>For the MANOVA test, we need to test two major assumptions. First, whether the response variables come from a multivariate normal distribution and second, for each group, the variance-covariance matrices for your response variables are equal in the population. The p-values are all less than 0.5 for the first test meaning that the null hypothesis, which states that the data came from a multivariate normal distribution, is not met. This assumption is violated and this is a limitation of the accuracy of the statistical tests we conducted. Since the first assumption was not met, I did not need to test the variance/covariance across the population because they will also not be met.</p>
<p>#Randomization test</p>
<pre class="r"><code>#Ho: mean insurance charges are the same between males and females
#Ha: mean insurance charges are not the same between males and females

#mean difference test
##test stastic
insurance%&gt;%group_by(sex)%&gt;%
  summarize(means=mean(charges))%&gt;%summarize(`mean_diff`=diff(means)) #males pay $1387.17 more for insurance charges on average.</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1     1387.</code></pre>
<pre class="r"><code>rand_dist&lt;-vector()
for(i in 1:5000){
new&lt;-data.frame(charges=sample(insurance$charges),sex=insurance$sex)
rand_dist[i]&lt;-mean(new[new$sex==&quot;male&quot;,]$charges)-
  mean(new[new$sex==&quot;female&quot;,]$charges)}

mean(rand_dist&gt;1387.172 | rand_dist&lt; -1387.172) #two-tailed p value</code></pre>
<pre><code>## [1] 0.0376</code></pre>
<pre class="r"><code>#plot
{hist(rand_dist,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = c(-1387.17, 1387.17),col=&quot;red&quot;)}</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" />
The null hypothesis is mean insurance charges are the same between males and females. The alternative hypothesis is mean insurance charges are the not the same between males and females. I conducted a mean difference test over 5,000 random permuations to create a random distribution. I calculated a p-value of 0.0366 which is less than 0.05, indicating that we can reject the null hypothesis. This means that there is an association between sex and insurance charges since the mean difference between them are significant.</p>
<p>#Linear Model</p>
<pre class="r"><code>#mean-center numeric variables
insurance$bmi_c &lt;- insurance$bmi - mean(insurance$bmi)
insurance$age_c &lt;- insurance$age - mean(insurance$age)

#linear regression model
fit&lt;-lm(charges ~ bmi_c*smoker, data=insurance)
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = charges ~ bmi_c * smoker, data = insurance)
##
## Residuals:
## Min 1Q Median 3Q Max
## -19768.0 -4400.7 -869.5 2957.7 31055.9
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 8435.24 188.87 44.661 &lt; 2e-16 ***
## bmi_c 83.35 31.27 2.666 0.00778 **
## smokeryes 23548.63 417.37 56.421 &lt; 2e-16 ***
## bmi_c:smokeryes 1389.76 66.78 20.810 &lt; 2e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 6161 on 1334 degrees of freedom
## Multiple R-squared: 0.7418, Adjusted R-squared: 0.7412
## F-statistic: 1277 on 3 and 1334 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>#regression plot
interact_plot(fit,bmi_c,smoker)</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>insurance %&gt;% ggplot(aes(bmi_c, charges, color=smoker))+geom_smooth(method=&quot;lm&quot;)+geom_point()</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-4-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#assumptions
resids&lt;-fit$residuals
fitvals&lt;-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color=&#39;red&#39;) #linearity and homoskedasticity</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-4-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>library(sandwich); library(lmtest)
bptest(fit) #heteroskedastic</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit
## BP = 6.9014, df = 3, p-value = 0.07511</code></pre>
<pre class="r"><code>shapiro.test(resids) #normality</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resids
## W = 0.91806, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>#uncorrected/Normal SEs
summary(fit)$coef</code></pre>
<pre><code>## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 8435.23531 188.87079 44.661408 3.776674e-267
## bmi_c 83.35056 31.26854 2.665637 7.777059e-03
## smokeryes 23548.63007 417.37433 56.420887 0.000000e+00
## bmi_c:smokeryes 1389.75570 66.78297 20.810031
1.608391e-83</code></pre>
<pre class="r"><code>#corrected/Robyst SEs
coeftest(fit, vcov=vcovHC(fit))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 8435.235 183.360 46.0037 &lt; 2.2e-16 ***
## bmi_c 83.351 28.610 2.9134 0.003635 **
## smokeryes 23548.630 453.102 51.9721 &lt; 2.2e-16 ***
## bmi_c:smokeryes 1389.756 78.604 17.6806 &lt; 2.2e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>#proportion of variation
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = charges ~ bmi_c * smoker, data = insurance)
##
## Residuals:
## Min 1Q Median 3Q Max
## -19768.0 -4400.7 -869.5 2957.7 31055.9
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 8435.24 188.87 44.661 &lt; 2e-16 ***
## bmi_c 83.35 31.27 2.666 0.00778 **
## smokeryes 23548.63 417.37 56.421 &lt; 2e-16 ***
## bmi_c:smokeryes 1389.76 66.78 20.810 &lt; 2e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 6161 on 1334 degrees of freedom
## Multiple R-squared: 0.7418, Adjusted R-squared: 0.7412
## F-statistic: 1277 on 3 and 1334 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>sum((fitvals-mean(insurance$charges))^2)/sum((insurance$charges-mean(insurance$charges))^2) #by hand</code></pre>
<pre><code>## [1] 0.741771</code></pre>
<p>The predicted insurance charge for an average BMI, non-smoker individual is $8,435.24. Controlling for smoker status, insurance charge increases by $83.35 for every one unit increase in BMI. Controlling for BMI, insurance charge is $23548.63 for smokers compared to non-smokers. The slope for BMI on insurance charge is $1389.76 higher for smokers compared to non-smokers.</p>
<p>Based on the scatterplot showing flaring and a cuving pattern, the linearity assumption is not met. Based on the Breusch-Pagan test, the data does meet the homoskedastic assumption. Based on the Shapiro-Wilk test producing p-value of less than 0.05, the normality assumption is also not met for this data. These are all limitations of my statisical model.</p>
<p>After using robust standard errors, the standard errors decreased for the intercept and BMI and increased for smoker status and the interaction variable. Overall, the p-values incresed as well. Using robust standard erros give us more accurate p-values and allows fitting of the model even in the presence of heteroskedacity.</p>
<p>The R-squared value is 0.7418 and the adjusted R-squared value is 0.7412. This can be interpreted as 74.12% of variability of charges are based on these two explanatory variables, BMI and smoker status.</p>
<p>#Bootstrappped standard errors</p>
<pre class="r"><code>samp_distn&lt;-replicate(5000, {
boot_dat&lt;-insurance[sample(nrow(insurance),replace=TRUE),]
fit&lt;-glm(charges ~ bmi_c * smoker, data=boot_dat)
coef(fit)
})
## Booststrapped SEs (resampling observations)
samp_distn%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)    bmi_c smokeryes bmi_c:smokeryes
## 1    184.4034 28.81325  447.8529        76.33466</code></pre>
<pre class="r"><code>#uncorrected/Normal SEs
summary(fit)$coef</code></pre>
<pre><code>## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 8435.23531 188.87079 44.661408 3.776674e-267
## bmi_c 83.35056 31.26854 2.665637 7.777059e-03
## smokeryes 23548.63007 417.37433 56.420887 0.000000e+00
## bmi_c:smokeryes 1389.75570 66.78297 20.810031
1.608391e-83</code></pre>
<pre class="r"><code>#corrected/Robyst SEs
coeftest(fit, vcov=vcovHC(fit))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 8435.235 183.360 46.0037 &lt; 2.2e-16 ***
## bmi_c 83.351 28.610 2.9134 0.003635 **
## smokeryes 23548.630 453.102 51.9721 &lt; 2.2e-16 ***
## bmi_c:smokeryes 1389.756 78.604 17.6806 &lt; 2.2e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>The bootstrapped standard errors are very similar to the Robust standard errors and relatively different compared to the original standard errors. The boostrapped SEs are slightly lower for the intercept, BMI, and BMI/smoker interaction compared to the robust standard errors but slighly higher for the smoker variable. Both the robust SEs and boostrapped SEs could be used to take into account that the data has heteroskedacity.</p>
<p>#Logistic Regression</p>
<pre class="r"><code>#create binary variable
insurance&lt;-insurance%&gt;%mutate(y=ifelse(smoker==&quot;yes&quot;,1,0))
logfit&lt;-glm(y~charges+age_c,data=insurance,family=binomial(link=&quot;logit&quot;))
coeftest(logfit)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -6.3208e+00 3.7496e-01 -16.857 &lt; 2.2e-16 ***
## charges 2.9480e-04 1.9248e-05 15.316 &lt; 2.2e-16 ***
## age_c -8.6145e-02 1.0637e-02 -8.099 5.543e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>#odds
exp(coef(logfit))</code></pre>
<pre><code>## (Intercept)     charges       age_c 
##  0.00179855  1.00029485  0.91746076</code></pre>
<pre class="r"><code>#confusion matrix
probs&lt;-predict(logfit,type=&quot;response&quot;)
table(predict=as.numeric(probs&gt;.5),truth=insurance$y)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict    0    1  Sum
##     0   1007   73 1080
##     1     57  201  258
##     Sum 1064  274 1338</code></pre>
<pre class="r"><code>#accuracy: 0.9028401
(1007+201)/1338</code></pre>
<pre><code>## [1] 0.9028401</code></pre>
<pre class="r"><code>#sensitivity/TPR: 0.7335766
201/274</code></pre>
<pre><code>## [1] 0.7335766</code></pre>
<pre class="r"><code>#specificity/TNR: 0.9464286
1007/1064</code></pre>
<pre><code>## [1] 0.9464286</code></pre>
<pre class="r"><code>#precision/PPV: 0.7790698
201/258</code></pre>
<pre><code>## [1] 0.7790698</code></pre>
<pre class="r"><code>#density plot
insurance$logit&lt;-predict(logfit)
insurance %&gt;% ggplot(aes(logit, fill=smoker))+geom_density(alpha=.3)+
  geom_vline(xintercept=0,lty=2)</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#ROC curve
library(plotROC)
ROCplot&lt;-ggplot(insurance)+geom_roc(aes(d=y,m=probs), n.cuts=0)
ROCplot</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-6-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.9759738</code></pre>
<p>Based on our logistic regression, insurance charge and age have a significant association on whether the individual is a smoker. Controlling for age, an increase in one dollar of insurance charge multiplies the odds of being a smoker by a factor of 1.0. Controlling for insurance charge, an increase in one year of age multiplies the odds of being a smoker by a factor of 0.917.</p>
<p>The accuracy of the model is 90.28% which is relatively good. The sensitivity is 73.36% and the specifcity is 94.64%. Since the specificty is much higher than the sensitivity, this means that the model is better at predicting false values than true values. The AUC is 0.976 which is considered great. This means that the probability that a random selected individual who is a smoker has a higher predicted probability than a randomly selected individual who is not a smoker. The plot is an ROC plot with sensitivity plotted against specificity. The curve lets us see the tradeoff between sensitivity and specificty and let’s us visualize the AUC. The higher the AUC, and this model looks like there is a relatively high AUC, means the model is a good classifier of distinguishing between the two groups, smoker and non-smoker.</p>
<p>#Logistic Regression with LASSO</p>
<pre class="r"><code>logfit2&lt;-glm(y~bmi_c+charges+children+age_c+sex+region,data=insurance,family=binomial(link=&quot;logit&quot;))
coeftest(logfit2)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -9.80922112 0.87240974 -11.2438 &lt; 2.2e-16
***
## bmi_c -0.37077591 0.04622992 -8.0203 1.055e-15 ***
## charges 0.00039342 0.00003114 12.6337 &lt; 2.2e-16 ***
## children -0.24393817 0.12779894 -1.9088 0.05629 .
## age_c -0.10057901 0.01331266 -7.5551 4.184e-14 ***
## sexmale 0.54784585 0.30179340 1.8153 0.06948 .
## regionnorthwest 0.14587682 0.39845914 0.3661 0.71429
## regionsoutheast 0.64194450 0.42059154 1.5263 0.12694
## regionsouthwest 0.31997422 0.43860613 0.7295 0.46568
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>prob2 &lt;- predict(logfit2, type=&quot;response&quot;)
class_diag(prob2, logfit2$y)</code></pre>
<pre><code>## acc sens spec ppv f1 auc
## 1 0.9603886 0.9452555 0.9642857 0.8720539 0.9071804
0.9865094</code></pre>
<pre class="r"><code>#10-fold CV
k=10

data1&lt;-insurance[sample(nrow(insurance)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(insurance)),breaks=k,labels=FALSE) #create folds
diags&lt;-NULL
for(i in 1:k){

train&lt;-data1[folds!=i,]
test&lt;-data1[folds==i,]
truth&lt;-test$y

fit&lt;-glm(y~bmi_c+charges+children+age_c+sex+region,data=train,family=&quot;binomial&quot;)
probs&lt;-predict(fit,newdata = test,type=&quot;response&quot;)

diags&lt;-rbind(diags,class_diag(probs,truth))
}
diags%&gt;%summarize_all(mean)</code></pre>
<pre><code>## acc sens spec ppv f1 auc
## 1 0.9521546 0.8936284 0.9638653 0.8453717 0.865519
0.9848734</code></pre>
<pre class="r"><code>#LASSO
library(glmnet)
y &lt;- as.matrix(insurance$y)
x &lt;- model.matrix(y~bmi_c+charges+children+age_c+sex+region, data=insurance)[,-1]
x&lt;-scale(x) 
cv&lt;-cv.glmnet(x,y,family=&quot;binomial&quot;)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 9 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                          s0
## (Intercept)     -2.92013700
## bmi_c           -1.22491565
## charges          3.33887023
## children        -0.02645608
## age_c           -0.85892304
## sexmale          0.01775259
## regionnorthwest  .         
## regionsoutheast  .         
## regionsouthwest  .</code></pre>
<pre class="r"><code>#10 fold using only LASSO selected variables
k=10
data1&lt;-insurance[sample(nrow(insurance)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(insurance)),breaks=k,labels=F) #create folds
diags&lt;-NULL
for(i in 1:k){
  train &lt;- data1[folds!=i,] #create training set (all but fold i)
  test &lt;- data1[folds==i,] #create test set (just fold i)
  truth &lt;- test$y #save truth labels from fold i
  fit3 &lt;- glm(y~bmi_c+charges+age_c,
             data=train, family=&quot;binomial&quot;)
  probs &lt;- predict(fit3, newdata=test, type=&quot;response&quot;)
  diags&lt;-rbind(diags,class_diag(probs,truth))
}
diags%&gt;%summarize_all(mean)</code></pre>
<pre><code>## acc sens spec ppv f1 auc
## 1 0.952149 0.9053051 0.9647643 0.8634927 0.8815328
0.9861011</code></pre>
<p>This new model with all the variables has an accuracy of 96.04%, sensitivity of 94.52%, specificity of 96.42%, precision of 98.65%, and an AUC of 0.986. All of these values are really high indicating that this model is a good predictor of distinguishing between smokers and nonn-smokers. When doing the out-of-sample model, the accuracy is 95.59%, sensitivity of 92.56%, specificity of 96.43%, precision of 86.82%, and an AUC of 98.57%. These values are almost exactly the same as the diagnostic values of the in-sample model. This means our original model was not doing a lot of overfitting and is a relatively accurate model to use.</p>
<p>When performing the LASSO, there the most predictive variables were BMI, insurance charges, and age. For my 10-fold CV, there was an accuracy of 95.51%, sensitivity of 91.49%, specificity of 96.51%, precision of 87.53%, and an AUC of 0.985. These results are surprisingly similar to the model with all variables. The specificity and precision slightly increased from previous model’s out-of-sample results while the AUC remained the same. This means that this model is slightly better at predicting both true values and false values. Overall, both models’ AUCs are considered great meaning they have a high probability of predicting a smoker from a non-smoker.</p>
</div>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/docs.min.js"></script>
<script src="/js/main.js"></script>

<script src="/js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
